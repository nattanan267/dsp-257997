{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandasql as psql\n",
    "from geopy.geocoders import Nominatim\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['activity_type', 'provider', 'local_patient_identifier', 'lsoa', 'hrg',\n",
      "       'hrg_description', 'fin_year', 'fin_month', 'activity_date',\n",
      "       'independent_sector'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(\"./data/Cataracts_2325_patient_level.xlsx\", engine=\"openpyxl\")\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "df['independent_sector'] = df['independent_sector'].str.strip().str.title()\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activity_type                  0\n",
      "provider                       0\n",
      "local_patient_identifier       0\n",
      "lsoa                        6124\n",
      "hrg                            0\n",
      "hrg_description                0\n",
      "fin_year                       0\n",
      "fin_month                      0\n",
      "activity_date                  0\n",
      "independent_sector             0\n",
      "provider_type                  0\n",
      "hrg_type                       0\n",
      "cc_score                       0\n",
      "complexity                     0\n",
      "needs_ga                       0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p_/9q2bvzqj04g1v63p4rjk_cxr0000gn/T/ipykernel_51427/2946627899.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned[\"needs_ga\"] = np.where(\n"
     ]
    }
   ],
   "source": [
    "df['activity_date'] = pd.to_datetime(df['activity_date'], errors='coerce')\n",
    "df['independent_sector'] = df['independent_sector'].map({'Yes': True, 'No': False})\n",
    "df['provider_type'] = df['independent_sector'].map({True: 'Independent', False : 'NHS'})\n",
    "\n",
    "def classify_hrg_detail(hrg_code):\n",
    "    hrg_map = {\n",
    "        'BZ30A': ('Complex', 'CC2+', 'High'),\n",
    "        'BZ30B': ('Complex', 'CC0-1', 'Medium'),\n",
    "        'BZ31A': ('Very Major', 'CC2+', 'High'),\n",
    "        'BZ31B': ('Very Major', 'CC0-1', 'Medium'),\n",
    "        'BZ32A': ('Intermediate', 'CC2+', 'Medium'),\n",
    "        'BZ32B': ('Intermediate', 'CC0-1', 'Medium'),\n",
    "        'BZ33Z': ('Minor', 'NA', 'Low'),\n",
    "        'BZ34A': ('Phaco', 'CC4+', 'High'),\n",
    "        'BZ34B': ('Phaco', 'CC2-3', 'Medium'),\n",
    "        'BZ34C': ('Phaco', 'CC0-1', 'Low')\n",
    "    }\n",
    "    return hrg_map.get(hrg_code, ('Unknown', 'Unknown', 'Unknown'))\n",
    "\n",
    "df[['hrg_type', 'cc_score', 'complexity']] = df['hrg'].apply(\n",
    "    lambda x: pd.Series(classify_hrg_detail(x))\n",
    ")\n",
    "\n",
    "df['local_patient_identifier'] = df['local_patient_identifier'].fillna(\n",
    "    df.index.astype(str) + \"_\" + df['activity_date'].astype(str)\n",
    ")\n",
    "\n",
    "# df[['fin_year_start', 'fin_year_end']] = df['fin_year'].str.split('/', expand=True).astype(int)\n",
    "\n",
    "\n",
    "df_cleaned = df.drop_duplicates(\n",
    "    subset=[\"activity_date\", \"local_patient_identifier\"], keep=\"first\"\n",
    ")\n",
    "\n",
    "df_cleaned[\"needs_ga\"] = np.where(\n",
    "    (df_cleaned[\"complexity\"] == \"High\") & (np.random.rand(len(df_cleaned)) < 0.3),\n",
    "    True,\n",
    "    False\n",
    ")\n",
    "\n",
    "print(df_cleaned.isnull().sum())\n",
    "\n",
    "df_cleaned.to_csv('./data/Cataracts_2325_patient_level_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p_/9q2bvzqj04g1v63p4rjk_cxr0000gn/T/ipykernel_51427/1442926436.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['provider_clean'] = df_cleaned['provider'].apply(clean_name)\n"
     ]
    }
   ],
   "source": [
    "df_provider_info = pd.read_csv(\"./data/National_cataract_audit_year_3_data.csv\")\n",
    "\n",
    "df_provider_info.columns\n",
    "\n",
    "def clean_name(x):\n",
    "    if isinstance(x, str):\n",
    "        return x.strip().lower().replace('–', '-').replace('—', '-')\n",
    "    return x\n",
    "\n",
    "df_cleaned['provider_clean'] = df_cleaned['provider'].apply(clean_name)\n",
    "df_provider_info['TrustName_clean'] = df_provider_info['TrustName'].apply(clean_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrustName_clean\n",
       "care uk                                                  9\n",
       "spamedica                                                8\n",
       "portsmouth hospitals nhs trust                           1\n",
       "bolton nhs foundation trust                              1\n",
       "james paget university hospitals nhs foundation trust    1\n",
       "northampton general hospital nhs trust                   1\n",
       "united lincolnshire hospitals nhs trust                  1\n",
       "county durham and darlington nhs foundation trust        1\n",
       "east suffolk and north essex nhs foundation trust        1\n",
       "east kent hospitals university nhs foundation trust      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_provider_info['TrustName_clean'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- จำนวนผู้ป่วยทั้งหมด / รายปี / รายเดือน \n",
    "- สัดส่วนผู้ป่วยที่ไป Independent vs NHS\n",
    "- ความซับซ้อนของเคสที่แต่ละ Provider ได้รับ\n",
    "- อัตราส่วน Provider → NHS vs Independent (Top 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of patient group by year and month\n",
    "q1 = \"\"\"\n",
    "select  strftime('%Y', activity_date) as year,\n",
    "        strftime('%m', activity_date) as month,\n",
    "        count(*) as total_patients \n",
    "from df_cleaned\n",
    "group by year, month\n",
    "order by year, month\n",
    "\"\"\"\n",
    "r1 = psql.sqldf(q1, locals())\n",
    "\n",
    "# q2 = \"\"\"\n",
    "# select activity_date, local_patient_identifier, hrg_description, count(*) as count\n",
    "# from df_cleaned\n",
    "# group by activity_date, local_patient_identifier, hrg_description\n",
    "# having count > 1\n",
    "# \"\"\"\n",
    "\n",
    "# patient ratio Independent vs NHS\n",
    "q2 = \"\"\"\n",
    "select \n",
    "    (select count(*) \n",
    "     from df_cleaned \n",
    "     where provider_type = 'Independent') * 1.0 /\n",
    "    (select count(*)\n",
    "     from df_cleaned \n",
    "     where provider_type = 'NHS') as ind_vs_nhs_ratio\n",
    "\"\"\"\n",
    "r2 = psql.sqldf(q2, locals())\n",
    "\n",
    "# total patient od indeoendent and NHS sector\n",
    "q3 = \"\"\"\n",
    "select \n",
    "    (select count(*)\n",
    "     from df_cleaned\n",
    "     where provider_type = 'Independent') as total_indendent, \n",
    "    (select count(*)\n",
    "     from df_cleaned\n",
    "     where provider_type = 'NHS') as total_nhs\n",
    "\"\"\"\n",
    "r3 = psql.sqldf(q3, locals())\n",
    "\n",
    "# number of patient group by hrg_description and provider type\n",
    "q4 = \"\"\"\n",
    "select strftime('%Y', activity_date) as year,\n",
    "       provider_type, \n",
    "       hrg_type, complexity, \n",
    "       hrg_description, \n",
    "       count(*) as total\n",
    "from df_cleaned\n",
    "group by hrg_description, provider_type, year\n",
    "order by provider_type, year\n",
    "\"\"\"\n",
    "r4 = psql.sqldf(q4, locals())\n",
    "\n",
    "# number of patient group by provider \n",
    "q5 = \"\"\"\n",
    "select provider, provider_type,count(*) as total\n",
    "from df_cleaned\n",
    "group by provider\n",
    "order by provider_type, total desc\n",
    "\"\"\"\n",
    "r5 = psql.sqldf(q5, locals())\n",
    "\n",
    "# number of patient group by provider, hrg_description, fin_month, fin_year\n",
    "q6 = \"\"\"\n",
    "select provider, hrg, hrg_description, fin_year, fin_month, count(*)\n",
    "from df_cleaned\n",
    "group by provider, hrg_description, fin_month, fin_year\n",
    "order by provider\n",
    "\"\"\"\n",
    "r6 = psql.sqldf(q6, locals())\n",
    "\n",
    "q7 = \"\"\"\n",
    "with provider_trust as (\n",
    "     select TrustName, \n",
    "          ITCLocation, \n",
    "          ODSCode, \n",
    "          round(NumberHESOperations/3.0, 1) as SlotsPerYear, \n",
    "          round(NumberHESOperations/156.0, 1) as SlotsPerWeek,\n",
    "          round(NumberHESOperations/1092.0, 1) as SlotsPerDay,\n",
    "          NumberOfSurgeons\n",
    "          from df_provider_info\n",
    "),\n",
    "provider_mapping as (\n",
    "     select distinct \n",
    "          c.provider,\n",
    "          case when c.independent_sector = 1 then 'true'\n",
    "               when c.independent_sector = 0 then 'false'\n",
    "               else 'NA'\n",
    "          end as is_nhs,\n",
    "          p.*\n",
    "          from df_cleaned as c\n",
    "          left join provider_trust as p\n",
    "               on lower(c.provider) like lower(p.TrustName || '%')\n",
    "),\n",
    "provider_mapping_trust as (\n",
    "     select distinct\n",
    "          m.provider,\n",
    "          m.ODSCode,\n",
    "          m.TrustName,\n",
    "          m.is_nhs,\n",
    "          p.SlotsPerYear, \n",
    "          p.SlotsPerWeek,\n",
    "          p.SlotsPerDay,\n",
    "          p.NumberOfSurgeons,\n",
    "          p.ITCLocation,\n",
    "          case \n",
    "               when lower(m.provider) = lower(p.TrustName)\n",
    "               then 1\n",
    "               else 0\n",
    "          end as flag_1,\n",
    "          case \n",
    "               when m.provider LIKE '%' || p.ITCLocation || '%' \n",
    "                    AND m.ODSCode = p.ODSCode\n",
    "               then 1\n",
    "               else 0\n",
    "          end as flag_2\n",
    "     from provider_mapping as m\n",
    "     left join provider_trust as p\n",
    "          on m.ODSCode = p.ODSCode\n",
    ")\n",
    "select distinct\n",
    "     provider,\n",
    "     is_nhs,\n",
    "     ODSCode,\n",
    "     TrustName,\n",
    "     ITCLocation,\n",
    "     SlotsPerYear,\n",
    "     SlotsPerWeek,\n",
    "     SlotsPerDay,\n",
    "     NumberOfSurgeons\n",
    "from provider_mapping_trust\n",
    "where flag_2 = 1\n",
    "\n",
    "union\n",
    "\n",
    "select distinct\n",
    "     provider,\n",
    "     is_nhs,\n",
    "     ODSCode,\n",
    "     TrustName,\n",
    "     null as ITCLocation,\n",
    "     case when flag_1 = 1 then SlotsPerYear else null end as SlotsPerYear,\n",
    "     case when flag_1 = 1 then SlotsPerWeek else null end as SlotsPerWeek,\n",
    "     case when flag_1 = 1 then SlotsPerDay else null end as SlotsPerDay,\n",
    "     case when flag_1 = 1 then NumberOfSurgeons else null end as NumberOfSurgeons\n",
    "from provider_mapping_trust\n",
    "where provider NOT IN (\n",
    "     select provider \n",
    "     from provider_mapping_trust \n",
    "     where flag_2 = 1\n",
    "     )\n",
    "\"\"\"\n",
    "r7 = psql.sqldf(q7, locals())\n",
    "r7.to_csv('./data/provider.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_provider = pd.read_csv('./data/provider.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "q8 = \"\"\"\n",
    "with map_slot as (\n",
    "       select provider,\n",
    "              round(count(*) * 1.0 / 156.0, 1) as SlotsPerWeek,\n",
    "              round(count(*) * 1.0 / 3.0, 1) as SlotsPerYear,\n",
    "              round(count(*) * 1.0 / 1092.0, 1) as SlotsPerDay\n",
    "       from df_cleaned\n",
    "       group by provider\n",
    ")\n",
    "select p.provider,\n",
    "       case when p.is_nhs = 1 then 'true'\n",
    "               when p.is_nhs = 0 then 'false'\n",
    "               else 'NA'\n",
    "       end as is_nhs,\n",
    "       COALESCE(p.SlotsPerYear, m.SlotsPerYear) AS SlotsPerYear,\n",
    "       COALESCE(p.SlotsPerWeek, m.SlotsPerWeek) AS SlotsPerWeek,\n",
    "       COALESCE(p.SlotsPerDay, m.SlotsPerDay) AS SlotsPerDay\n",
    "from df_provider as p\n",
    "left join map_slot as m\n",
    "       on p.provider = m.provider\n",
    "\n",
    "\"\"\"\n",
    "r8 = psql.sqldf(q8, locals())\n",
    "r8.to_csv('./data/provider2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_provider_final = pd.read_csv('./data/provider2.csv')\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"ptl-phase1-model\")\n",
    "\n",
    "def geocode_provider(name):\n",
    "    try:\n",
    "        location = geolocator.geocode(f\"{name}, United Kingdom\", timeout=10)\n",
    "        if location:\n",
    "            return location.latitude, location.longitude\n",
    "        else:\n",
    "            return None, None\n",
    "    except:\n",
    "        return None, None\n",
    "\n",
    "df_provider_final[['lat', 'long']] = df_provider_final['provider'].apply(\n",
    "    lambda x: pd.Series(geocode_provider(x))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_provider_final.to_csv('./data/provider_lat_long.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "q9 = \"\"\"\n",
    "select  provider,\n",
    "        case when independent_sector = 1 then 'true'\n",
    "             when independent_sector = 0 then 'false'\n",
    "             else 'NA'\n",
    "        end as is_nhs,\n",
    "        strftime('%Y-%W', activity_date) AS year_week,\n",
    "        count(*) AS all_throughput,\n",
    "        sum(case when complexity = 'Low' then 1 else 0 end) AS low_complexity,\n",
    "        sum(case when complexity = 'Medium' then 1 else 0 end) AS medium_complexity,\n",
    "        sum(case when complexity = 'High' then 1 else 0 end) AS high_complexity\n",
    "from df_cleaned\n",
    "group by year_week, provider\n",
    "order by year_week, provider\n",
    "\"\"\"\n",
    "r9 = psql.sqldf(q9, locals())\n",
    "r9.to_csv(\"./data/provider_weekly_throughput.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_provider_lat_long_final = pd.read_csv('./data/provider_lat_long.csv')\n",
    "\n",
    "df_provider_lat_long_final[\"SlotsPerDay\"] = pd.to_numeric(df_provider_lat_long_final[\"SlotsPerDay\"], errors=\"coerce\")\n",
    "\n",
    "df_provider_lat_long_final[\"SlotsPerDay\"] = df_provider_lat_long_final[\"SlotsPerDay\"].fillna(0)\n",
    "\n",
    "df_provider_lat_long_final[\"SlotsPerDay\"] = df_provider_lat_long_final[\"SlotsPerDay\"].apply(lambda x: max(1, round(x, 1)))\n",
    "\n",
    "# df_provider_lat_long_final.to_csv('./data/provider_lat_long.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def _ensure_cols(df: pd.DataFrame, cols: List[str]):\n",
    "    missing = [c for c in cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"DataFrame is missing required columns: {missing}\")\n",
    "\n",
    "def _pick_policies(df: pd.DataFrame, wanted: Optional[List[str]]) -> pd.DataFrame:\n",
    "    if not wanted:\n",
    "        return df.copy()\n",
    "    return df[df[\"policy\"].isin(wanted)].copy()\n",
    "\n",
    "def _safe_round(x, nd=2):\n",
    "    try:\n",
    "        return round(float(x), nd)\n",
    "    except Exception:\n",
    "        return x\n",
    "\n",
    "def _compute_overall_share_to_nhs(row: pd.Series) -> float:\n",
    "    \"\"\"\n",
    "    ถ้าไม่มีคอลัมน์ overall_pct_to_nhs จะคำนวณแบบ approx:\n",
    "    ค่าเฉลี่ยของ {pct_low_to_nhs, pct_medium_to_nhs, pct_high_to_nhs}\n",
    "    (ถ้ามีสัดส่วนจำนวนผู้ป่วยต่อ complexity สามารถเปลี่ยนเป็น weighted mean ภายหลังได้)\n",
    "    \"\"\"\n",
    "    keys = [\"pct_low_to_nhs\", \"pct_medium_to_nhs\", \"pct_high_to_nhs\"]\n",
    "    vals = [row[k] for k in keys if k in row and pd.notna(row[k])]\n",
    "    return float(np.mean(vals)) if vals else np.nan\n",
    "\n",
    "\n",
    "def fig_avg_wait_by_policy(df: pd.DataFrame, outpath: Path):\n",
    "    _ensure_cols(df, [\"policy\", \"avg_wait\"])\n",
    "    d = df.copy().sort_values(\"avg_wait\", ascending=True)\n",
    "\n",
    "    plt.figure(figsize=(9, 5))\n",
    "    plt.bar(d[\"policy\"], d[\"avg_wait\"])\n",
    "    plt.xticks(rotation=30, ha=\"right\")\n",
    "    plt.ylabel(\"Average wait (days)\")\n",
    "    for i, v in enumerate(d[\"avg_wait\"]):\n",
    "        plt.text(i, v, f\"{_safe_round(v,1)}\", ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outpath, dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def fig_complexity_mix_stacked(df: pd.DataFrame, outpath: Path):\n",
    "    needed = [\n",
    "        \"policy\",\n",
    "        \"pct_low_to_nhs\", \"pct_low_to_private\",\n",
    "        \"pct_medium_to_nhs\", \"pct_medium_to_private\",\n",
    "        \"pct_high_to_nhs\", \"pct_high_to_private\",\n",
    "    ]\n",
    "    _ensure_cols(df, needed)\n",
    "    d = df.copy()\n",
    "\n",
    "    segments = [\n",
    "        (\"pct_low_to_nhs\", \"Low→NHS\"),\n",
    "        (\"pct_low_to_private\", \"Low→Private\"),\n",
    "        (\"pct_medium_to_nhs\", \"Med→NHS\"),\n",
    "        (\"pct_medium_to_private\", \"Med→Private\"),\n",
    "        (\"pct_high_to_nhs\", \"High→NHS\"),\n",
    "        (\"pct_high_to_private\", \"High→Private\"),\n",
    "    ]\n",
    "\n",
    "    plt.figure(figsize=(11, 6))\n",
    "    bottoms = [0.0] * len(d)\n",
    "    for col, label in segments:\n",
    "        vals = d[col].values\n",
    "        plt.bar(d[\"policy\"], vals, bottom=bottoms, label=label)\n",
    "        bottoms = [b + v for b, v in zip(bottoms, vals)]\n",
    "\n",
    "    plt.xticks(rotation=30, ha=\"right\")\n",
    "    plt.ylabel(\"Share of cases (%)\")\n",
    "    plt.legend(loc=\"upper right\", ncol=2, fontsize=9)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outpath, dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "def fig_tradeoff_scatter(df: pd.DataFrame, outpath: Path):\n",
    "    _ensure_cols(df, [\"policy\", \"avg_travel_distance_km\", \"avg_wait\"])\n",
    "    d = df.copy()\n",
    "\n",
    "    plt.figure(figsize=(7.5, 6))\n",
    "    plt.scatter(d[\"avg_travel_distance_km\"], d[\"avg_wait\"])\n",
    "    for _, row in d.iterrows():\n",
    "        plt.annotate(row[\"policy\"],\n",
    "                     (row[\"avg_travel_distance_km\"], row[\"avg_wait\"]),\n",
    "                     xytext=(3, 3), textcoords=\"offset points\", fontsize=9)\n",
    "    plt.xlabel(\"Avg travel distance (km)\")\n",
    "    plt.ylabel(\"Avg wait (days)\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outpath, dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "def fig_wait_by_complexity(df: pd.DataFrame, outpath: Path):\n",
    "    _ensure_cols(df, [\"policy\", \"avg_wait_low\", \"avg_wait_medium\", \"avg_wait_high\"])\n",
    "    d = df.copy()\n",
    "    d = d.sort_values(\"avg_wait\", ascending=True) if \"avg_wait\" in d.columns else d\n",
    "\n",
    "    labels = d[\"policy\"].tolist()\n",
    "    low = d[\"avg_wait_low\"].tolist()\n",
    "    med = d[\"avg_wait_medium\"].tolist()\n",
    "    high = d[\"avg_wait_high\"].tolist()\n",
    "\n",
    "    x = np.arange(len(labels))\n",
    "    width = 0.25\n",
    "\n",
    "    plt.figure(figsize=(11, 6))\n",
    "    plt.bar(x - width, low, width, label=\"Low\")\n",
    "    plt.bar(x,        med, width, label=\"Medium\")\n",
    "    plt.bar(x + width, high, width, label=\"High\")\n",
    "    plt.xticks(x, labels, rotation=30, ha=\"right\")\n",
    "    plt.ylabel(\"Average wait (days)\")\n",
    "    plt.legend()\n",
    "    for xi, v in zip(x - width, low):\n",
    "        plt.text(xi, v, f\"{_safe_round(v,1)}\", ha=\"center\", va=\"bottom\", fontsize=8)\n",
    "    for xi, v in zip(x, med):\n",
    "        plt.text(xi, v, f\"{_safe_round(v,1)}\", ha=\"center\", va=\"bottom\", fontsize=8)\n",
    "    for xi, v in zip(x + width, high):\n",
    "        plt.text(xi, v, f\"{_safe_round(v,1)}\", ha=\"center\", va=\"bottom\", fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outpath, dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "def plot_complexity_mix(df_summary: pd.DataFrame, policies_order=None, figsize=(12, 6), savepath=None):\n",
    "    need = [\n",
    "        \"policy\",\n",
    "        \"pct_low_to_nhs\",\"pct_low_to_private\",\n",
    "        \"pct_medium_to_nhs\",\"pct_medium_to_private\",\n",
    "        \"pct_high_to_nhs\",\"pct_high_to_private\",\n",
    "    ]\n",
    "    _ensure_cols(df_summary, need)\n",
    "\n",
    "    df = df_summary.copy()\n",
    "    if policies_order is None:\n",
    "        policies_order = df[\"policy\"].tolist()\n",
    "    df = df.set_index(\"policy\").loc[policies_order].reset_index()\n",
    "\n",
    "    x = np.arange(len(df))\n",
    "    width = 0.25\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # Low\n",
    "    low_nhs = df[\"pct_low_to_nhs\"].values\n",
    "    low_pri = df[\"pct_low_to_private\"].values\n",
    "    ax.bar(x - width, low_nhs, width, label=\"Low → NHS\")\n",
    "    ax.bar(x - width, low_pri, width, bottom=low_nhs, label=\"Low → Private\")\n",
    "\n",
    "    # Medium\n",
    "    med_nhs = df[\"pct_medium_to_nhs\"].values\n",
    "    med_pri = df[\"pct_medium_to_private\"].values\n",
    "    ax.bar(x, med_nhs, width, label=\"Med → NHS\")\n",
    "    ax.bar(x, med_pri, width, bottom=med_nhs, label=\"Med → Private\")\n",
    "\n",
    "    # High\n",
    "    hi_nhs = df[\"pct_high_to_nhs\"].values\n",
    "    hi_pri = df[\"pct_high_to_private\"].values\n",
    "    ax.bar(x + width, hi_nhs, width, label=\"High → NHS\")\n",
    "    ax.bar(x + width, hi_pri, width, bottom=hi_nhs, label=\"High → Private\")\n",
    "\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(df[\"policy\"], rotation=20, ha=\"right\")\n",
    "    ax.set_ylabel(\"Complexity distribution share (%)\")\n",
    "    ax.set_ylim(0, 120)  # กัน rounding overflow\n",
    "\n",
    "    ax.legend(ncol=3, fontsize=9, frameon=False, loc=\"upper left\", bbox_to_anchor=(0, 1.15))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if savepath:\n",
    "        plt.savefig(savepath, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def _ensure_cols(df: pd.DataFrame, cols):\n",
    "    missing = [c for c in cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns: {missing}\")\n",
    "\n",
    "def plot_avg_tariff_by_sector(\n",
    "    df_summary: pd.DataFrame,\n",
    "    policies_order=None,\n",
    "    figsize=(12, 4.5),\n",
    "    savepath=None,\n",
    "    show_gap_labels=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    วาดกราฟเปรียบเทียบ 'Avg tariff (NHS)' และ 'Avg tariff (Private)' ต่อ policy\n",
    "    คาดว่า df_summary มีคอลัมน์: policy, avg_tariff_nhs, avg_tariff_private\n",
    "    \"\"\"\n",
    "    _ensure_cols(df_summary, [\"policy\", \"avg_tariff_nhs\", \"avg_tariff_private\"])\n",
    "    df = df_summary.copy()\n",
    "\n",
    "    if policies_order is None:\n",
    "        policies_order = df[\"policy\"].tolist()\n",
    "    df = df.set_index(\"policy\").loc[policies_order].reset_index()\n",
    "\n",
    "    x = np.arange(len(df))\n",
    "    w = 0.38\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    b1 = ax.bar(x - w/2, df[\"avg_tariff_nhs\"], width=w, label=\"NHS\")\n",
    "    b2 = ax.bar(x + w/2, df[\"avg_tariff_private\"], width=w, label=\"Independent\")\n",
    "\n",
    "    ax.set_ylabel(\"Average tariff per case (£)\")\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(df[\"policy\"], rotation=20, ha=\"right\")\n",
    "    ax.legend()\n",
    "\n",
    "    # ใส่ตัวเลขบนแท่ง\n",
    "    for bars in (b1, b2):\n",
    "        for rect in bars:\n",
    "            h = rect.get_height()\n",
    "            ax.text(\n",
    "                rect.get_x() + rect.get_width()/2, h,\n",
    "                f\"{h:.0f}\", ha=\"center\", va=\"bottom\", fontsize=9\n",
    "            )\n",
    "\n",
    "    if show_gap_labels:\n",
    "        gaps = df[\"avg_tariff_private\"] - df[\"avg_tariff_nhs\"]\n",
    "        for i, g in enumerate(gaps):\n",
    "            ax.text(\n",
    "                x[i], max(df[\"avg_tariff_nhs\"][i], df[\"avg_tariff_private\"][i]) + 12,\n",
    "                f\"Δ£{g:.0f}\", ha=\"center\", va=\"bottom\", fontsize=9, color=\"gray\"\n",
    "            )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if savepath:\n",
    "        plt.savefig(savepath, dpi=200, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def tariff_gap_table(df_summary: pd.DataFrame, policies_order=None) -> pd.DataFrame:\n",
    "    \"\"\"ทำตารางสรุปตัวเลขไว้ใส่ในรายงาน/ภาคผนวก\"\"\"\n",
    "    _ensure_cols(df_summary, [\"policy\", \"avg_tariff_nhs\", \"avg_tariff_private\"])\n",
    "    df = df_summary.copy()\n",
    "    if policies_order is not None:\n",
    "        df = df.set_index(\"policy\").loc[policies_order].reset_index()\n",
    "    out = df[[\"policy\", \"avg_tariff_nhs\", \"avg_tariff_private\"]].copy()\n",
    "    out[\"gap_private_minus_nhs\"] = out[\"avg_tariff_private\"] - out[\"avg_tariff_nhs\"]\n",
    "    # ปัดให้สวย\n",
    "    return out.rename(columns={\n",
    "        \"avg_tariff_nhs\": \"Avg tariff NHS (£)\",\n",
    "        \"avg_tariff_private\": \"Avg tariff Independent (£)\",\n",
    "        \"gap_private_minus_nhs\": \"Δ (Ind − NHS) (£)\"\n",
    "    })\n",
    "\n",
    "def plot_wait_vs_share_nhs(df_summary: pd.DataFrame, policies_order=None, figsize=(10, 6), savepath=None):\n",
    "    _ensure_cols(df_summary, [\"policy\", \"avg_wait\",\n",
    "                              \"pct_low_to_nhs\", \"pct_medium_to_nhs\", \"pct_high_to_nhs\"])\n",
    "\n",
    "    df = df_summary.copy()\n",
    "    if \"overall_pct_to_nhs\" not in df.columns:\n",
    "        df[\"overall_pct_to_nhs\"] = df.apply(_compute_overall_share_to_nhs, axis=1)\n",
    "\n",
    "    if policies_order is None:\n",
    "        policies_order = df[\"policy\"].tolist()\n",
    "    df = df.set_index(\"policy\").loc[policies_order].reset_index()\n",
    "\n",
    "    x = df[\"overall_pct_to_nhs\"].values\n",
    "    y = df[\"avg_wait\"].values\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.scatter(x, y)\n",
    "    for xi, yi, name in zip(x, y, df[\"policy\"]):\n",
    "        ax.annotate(name, (xi, yi), textcoords=\"offset points\", xytext=(5, 4), fontsize=9)\n",
    "\n",
    "    ax.set_xlabel(\"% allocated to NHS (overall, approx)\")\n",
    "    ax.set_ylabel(\"Average waiting time (days)\")\n",
    "\n",
    "    if len(x) >= 2 and np.isfinite(x).all() and np.isfinite(y).all():\n",
    "        m, b = np.polyfit(x, y, 1)\n",
    "        xx = np.linspace(min(x), max(x), 100)\n",
    "        ax.plot(xx, m * xx + b, linestyle=\"--\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if savepath:\n",
    "        plt.savefig(savepath, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    return fig, ax\n",
    "\n",
    "def plot_seen_within(df: pd.DataFrame, policies_order=None, figsize=(12, 5), savepath=None):\n",
    "    need = [\"policy\", \"pct_seen_within_7_days\", \"pct_seen_within_30_days\", \"pct_seen_within_90_days\"]\n",
    "    _ensure_cols(df, need)\n",
    "\n",
    "    df = df.copy()\n",
    "    if policies_order is None:\n",
    "        policies_order = df[\"policy\"].tolist()\n",
    "    df = df.set_index(\"policy\").loc[policies_order].reset_index()\n",
    "\n",
    "    x = np.arange(len(df))\n",
    "    width = 0.25\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.bar(x - width, df[\"pct_seen_within_7_days\"], width, label=\"Within 7 days\")\n",
    "    ax.bar(x,        df[\"pct_seen_within_30_days\"], width, label=\"Within 30 days\")\n",
    "    ax.bar(x + width, df[\"pct_seen_within_90_days\"], width, label=\"Within 90 days\")\n",
    "\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(df[\"policy\"], rotation=20, ha=\"right\")\n",
    "    ax.set_ylabel(\"% of patients seen\")\n",
    "    ax.legend()\n",
    "\n",
    "    for xi, v in zip(x - width, df[\"pct_seen_within_7_days\"]):\n",
    "        ax.text(xi, v, f\"{v:.1f}\", ha=\"center\", va=\"bottom\", fontsize=8)\n",
    "    for xi, v in zip(x, df[\"pct_seen_within_30_days\"]):\n",
    "        ax.text(xi, v, f\"{v:.1f}\", ha=\"center\", va=\"bottom\", fontsize=8)\n",
    "    for xi, v in zip(x + width, df[\"pct_seen_within_90_days\"]):\n",
    "        ax.text(xi, v, f\"{v:.1f}\", ha=\"center\", va=\"bottom\", fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if savepath:\n",
    "        plt.savefig(savepath, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def plot_wait_ga_vs_nonga(df: pd.DataFrame, policies_order=None, figsize=(10, 5), savepath=None):\n",
    "    need = [\"policy\", \"avg_wait_ga\", \"avg_wait_non_ga\"]\n",
    "    _ensure_cols(df, need)\n",
    "\n",
    "    df = df.copy()\n",
    "    if policies_order is None:\n",
    "        policies_order = df[\"policy\"].tolist()\n",
    "    df = df.set_index(\"policy\").loc[policies_order].reset_index()\n",
    "\n",
    "    x = np.arange(len(df))\n",
    "    width = 0.35\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.bar(x - width/2, df[\"avg_wait_ga\"], width, label=\"GA patients\")\n",
    "    ax.bar(x + width/2, df[\"avg_wait_non_ga\"], width, label=\"Non-GA patients\")\n",
    "\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(df[\"policy\"], rotation=20, ha=\"right\")\n",
    "    ax.set_ylabel(\"Average wait (days)\")\n",
    "    ax.legend()\n",
    "\n",
    "    for xi, v in zip(x - width/2, df[\"avg_wait_ga\"]):\n",
    "        ax.text(xi, v, f\"{_safe_round(v,1)}\", ha=\"center\", va=\"bottom\", fontsize=8)\n",
    "    for xi, v in zip(x + width/2, df[\"avg_wait_non_ga\"]):\n",
    "        ax.text(xi, v, f\"{_safe_round(v,1)}\", ha=\"center\", va=\"bottom\", fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if savepath:\n",
    "        plt.savefig(savepath, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    return fig, ax\n",
    "\n",
    "def make_all_figures(\n",
    "    df: pd.DataFrame,\n",
    "    outdir: str = \"figs\",\n",
    "    policies_keep: Optional[List[str]] = None,\n",
    "    sort_for_readability: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    df: summary table (หนึ่งแถวต่อ policy)\n",
    "    policies_keep: รายชื่อ policy ที่จะโชว์ (จะคงลำดับตามที่ระบุ)\n",
    "    \"\"\"\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "    d = df.copy()\n",
    "\n",
    "    if policies_keep:\n",
    "        d = _pick_policies(d, policies_keep)\n",
    "        d[\"policy\"] = pd.Categorical(d[\"policy\"], categories=policies_keep, ordered=True)\n",
    "        d = d.sort_values(\"policy\")\n",
    "\n",
    "    d[\"policy\"] = d[\"policy\"].astype(str).str.strip()\n",
    "\n",
    "    p1  = Path(outdir) / \"nappear/fig1_avg_wait_by_policy_nappear.png\"\n",
    "    p2  = Path(outdir) / \"nappear/fig2_complexity_mix_stacked_nappear.png\"\n",
    "    p3  = Path(outdir) / \"nappear/fig3_tradeoff_wait_vs_distance_nappear.png\"\n",
    "    p4  = Path(outdir) / \"nappear/fig4_wait_by_complexity_nappear.png\"\n",
    "    p5a = Path(outdir) / \"nappear/fig5a_complexity_mix_by_group_nappear.png\"\n",
    "    p5b = Path(outdir) / \"nappear/fig5b_avg_tariff_by_sector_nappear.png\"\n",
    "    pWT = Path(outdir) / \"nappear/fig_wait_vs_nhs_share_nappear.png\"\n",
    "    p6a = Path(outdir) / \"nappear/fig6a_seen_within_nappear.png\"\n",
    "    p6b = Path(outdir) / \"nappear/fig6b_wait_ga_vs_non_ga_nappear.png\"\n",
    "\n",
    "    fig_avg_wait_by_policy(d, p1)\n",
    "    fig_complexity_mix_stacked(d, p2)\n",
    "    fig_tradeoff_scatter(d, p3)\n",
    "    fig_wait_by_complexity(d, p4)\n",
    "    plot_complexity_mix(d, policies_order=list(d[\"policy\"]), savepath=p5a)\n",
    "    # วาด NHS vs Independent tariff (ต้องมีคอลัมน์ avg_tariff_nhs & avg_tariff_private)\n",
    "    plot_avg_tariff_by_sector(d, policies_order=list(d[\"policy\"]), savepath=p5b)\n",
    "    plot_wait_vs_share_nhs(d, policies_order=list(d[\"policy\"]), savepath=pWT)\n",
    "    plot_seen_within(d, policies_order=list(d[\"policy\"]), savepath=p6a)\n",
    "    plot_wait_ga_vs_nonga(d, policies_order=list(d[\"policy\"]), savepath=p6b)\n",
    "\n",
    "    print(\"[Saved]\")\n",
    "    for p in [p1, p2, p3, p4, p5a, p5b, pWT, p6a, p6b]:\n",
    "        print(p.resolve())\n",
    "\n",
    "\n",
    "def make_all_figures_from_csv(\n",
    "    csv_path: str,\n",
    "    outdir: str = \"figs\",\n",
    "    policies_keep: Optional[List[str]] = None,\n",
    "):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    make_all_figures(df, outdir=outdir, policies_keep=policies_keep)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Saved]\n",
      "/Users/nattanan/Desktop/Dissertation/ptl_sim/figs/nappear/fig1_avg_wait_by_policy_nappear.png\n",
      "/Users/nattanan/Desktop/Dissertation/ptl_sim/figs/nappear/fig2_complexity_mix_stacked_nappear.png\n",
      "/Users/nattanan/Desktop/Dissertation/ptl_sim/figs/nappear/fig3_tradeoff_wait_vs_distance_nappear.png\n",
      "/Users/nattanan/Desktop/Dissertation/ptl_sim/figs/nappear/fig4_wait_by_complexity_nappear.png\n",
      "/Users/nattanan/Desktop/Dissertation/ptl_sim/figs/nappear/fig5a_complexity_mix_by_group_nappear.png\n",
      "/Users/nattanan/Desktop/Dissertation/ptl_sim/figs/nappear/fig5b_avg_tariff_by_sector_nappear.png\n",
      "/Users/nattanan/Desktop/Dissertation/ptl_sim/figs/nappear/fig_wait_vs_nhs_share_nappear.png\n",
      "/Users/nattanan/Desktop/Dissertation/ptl_sim/figs/nappear/fig6a_seen_within_nappear.png\n",
      "/Users/nattanan/Desktop/Dissertation/ptl_sim/figs/nappear/fig6b_wait_ga_vs_non_ga_nappear.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./data/summary_results/summary_all_policies_old.csv\")\n",
    "\n",
    "keep = [\n",
    "    # \"Baseline\",\n",
    "    \"Shared Equal\",\n",
    "    \"Fastest First\",\n",
    "    # \"Complexity Balanced\",\n",
    "    # \"Fee Biased\",\n",
    "    \"Neutral Fee\",\n",
    "    # \"ML Balanced (wait+dist+util)\",\n",
    "]\n",
    "\n",
    "\n",
    "make_all_figures(df, outdir=\"figs\", policies_keep=keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved figures to: /Users/nattanan/Desktop/Dissertation/ptl_sim/fig_out\n"
     ]
    }
   ],
   "source": [
    "# plot_frontier.py\n",
    "\n",
    "CSV_PATH = Path(\"/Users/nattanan/Desktop/Dissertation/ptl_sim/data/summary_results/nhs_share_frontier_ci_by_target.csv\")\n",
    "OUT_DIR = Path(\"./fig_out\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "required_cols = [\n",
    "    \"target_high_to_private_share\",\n",
    "    \"avg_wait_mean\", \"avg_wait_ci_half\",\n",
    "    \"nhs_share_mean\", \"nhs_share_ci_half\",\n",
    "    \"avg_travel_distance_mean\", \"avg_travel_distance_ci_half\",\n",
    "]\n",
    "missing = [c for c in required_cols if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing columns in CSV: {missing}\")\n",
    "\n",
    "x = df[\"target_high_to_private_share\"]\n",
    "\n",
    "def plot_with_ci(x, y_mean, y_ci, xlabel, ylabel, title, outfile):\n",
    "    y_lo = y_mean - y_ci\n",
    "    y_hi = y_mean + y_ci\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(x, y_mean, marker=\"o\")\n",
    "    plt.fill_between(x, y_lo, y_hi, alpha=0.2, linewidth=0)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUT_DIR / f\"{outfile}.png\", dpi=300)\n",
    "    plt.savefig(OUT_DIR / f\"{outfile}.pdf\")\n",
    "    plt.close()\n",
    "\n",
    "plot_with_ci(\n",
    "    x=x,\n",
    "    y_mean=df[\"avg_wait_mean\"],\n",
    "    y_ci=df[\"avg_wait_ci_half\"],\n",
    "    xlabel=\"Target High→Private share\",\n",
    "    ylabel=\"Average wait (days)\",\n",
    "    title=\"Average wait vs Target High→Private share\",\n",
    "    outfile=\"frontier_avg_wait\"\n",
    ")\n",
    "\n",
    "plot_with_ci(\n",
    "    x=x,\n",
    "    y_mean=df[\"nhs_share_mean\"],\n",
    "    y_ci=df[\"nhs_share_ci_half\"],\n",
    "    xlabel=\"Target High→Private share\",\n",
    "    ylabel=\"NHS share (%)\",\n",
    "    title=\"NHS share vs Target High→Private share\",\n",
    "    outfile=\"frontier_nhs_share\"\n",
    ")\n",
    "\n",
    "plot_with_ci(\n",
    "    x=x,\n",
    "    y_mean=df[\"avg_travel_distance_mean\"],\n",
    "    y_ci=df[\"avg_travel_distance_ci_half\"],\n",
    "    xlabel=\"Target High→Private share\",\n",
    "    ylabel=\"Average travel distance (km)\",\n",
    "    title=\"Travel distance vs Target High→Private share\",\n",
    "    outfile=\"frontier_travel_distance\"\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(6.2, 8), sharex=True)\n",
    "\n",
    "def _subplot(ax, x, y_mean, y_ci, ylabel, title):\n",
    "    y_lo, y_hi = y_mean - y_ci, y_mean + y_ci\n",
    "    ax.plot(x, y_mean, marker=\"o\")\n",
    "    ax.fill_between(x, y_lo, y_hi, alpha=0.2, linewidth=0)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title, pad=6)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "_subplot(\n",
    "    axes[0], x,\n",
    "    df[\"avg_wait_mean\"], df[\"avg_wait_ci_half\"],\n",
    "    \"Avg wait (days)\", \"Average wait\"\n",
    ")\n",
    "_subplot(\n",
    "    axes[1], x,\n",
    "    df[\"nhs_share_mean\"], df[\"nhs_share_ci_half\"],\n",
    "    \"NHS share (%)\", \"NHS share\"\n",
    ")\n",
    "_subplot(\n",
    "    axes[2], x,\n",
    "    df[\"avg_travel_distance_mean\"], df[\"avg_travel_distance_ci_half\"],\n",
    "    \"Travel (km)\", \"Average travel distance\"\n",
    ")\n",
    "\n",
    "axes[-1].set_xlabel(\"Target High→Private share\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUT_DIR / \"frontier_combined.png\", dpi=300)\n",
    "plt.savefig(OUT_DIR / \"frontier_combined.pdf\")\n",
    "plt.close()\n",
    "\n",
    "print(\"Saved figures to:\", OUT_DIR.resolve())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
